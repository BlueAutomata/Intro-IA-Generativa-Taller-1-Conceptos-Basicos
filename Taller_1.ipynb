{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90fd06a3",
   "metadata": {},
   "source": [
    "# Taller 1 Conceptos bÃ¡sicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f2bfc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\guill\\Documents\\GitHub\\Intro-IA-Generativa-Taller-1-Conceptos-Basicos>() \n"
     ]
    }
   ],
   "source": [
    "!myenv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46b9e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: numpy==1.26.4 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: transformers==4.44.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 3)) (4.44.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 4)) (3.9.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 5)) (3.7.5)\n",
      "Requirement already satisfied: torch in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 7)) (2.3.1)\n",
      "Requirement already satisfied: nbdime in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from -r requirements.txt (line 8)) (4.0.2)\n",
      "Collecting model2vec (from -r requirements.txt (line 9))\n",
      "  Downloading model2vec-0.2.3-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.44.2->-r requirements.txt (line 3)) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.44.2->-r requirements.txt (line 3)) (0.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.44.2->-r requirements.txt (line 3)) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.44.2->-r requirements.txt (line 3)) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.44.2->-r requirements.txt (line 3)) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.44.2->-r requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.44.2->-r requirements.txt (line 3)) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.44.2->-r requirements.txt (line 3)) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers==4.44.2->-r requirements.txt (line 3)) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2024.2)\n",
      "Requirement already satisfied: click in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->-r requirements.txt (line 4)) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->-r requirements.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (0.12.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (2.6.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (65.5.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy->-r requirements.txt (line 5)) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 7)) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 7)) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 7)) (3.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 7)) (2024.6.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch->-r requirements.txt (line 7)) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbdime->-r requirements.txt (line 8)) (0.4.6)\n",
      "Requirement already satisfied: gitpython!=2.1.4,!=2.1.5,!=2.1.6 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbdime->-r requirements.txt (line 8)) (3.1.43)\n",
      "Requirement already satisfied: jupyter-server in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbdime->-r requirements.txt (line 8)) (2.14.2)\n",
      "Requirement already satisfied: jupyter-server-mathjax>=0.2.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbdime->-r requirements.txt (line 8)) (0.2.6)\n",
      "Requirement already satisfied: nbformat in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbdime->-r requirements.txt (line 8)) (5.10.4)\n",
      "Requirement already satisfied: pygments in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbdime->-r requirements.txt (line 8)) (2.18.0)\n",
      "Requirement already satisfied: tornado in c:\\users\\guill\\appdata\\roaming\\python\\python311\\site-packages (from nbdime->-r requirements.txt (line 8)) (6.4.1)\n",
      "Requirement already satisfied: rich in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from model2vec->-r requirements.txt (line 9)) (13.9.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from model2vec->-r requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython!=2.1.4,!=2.1.5,!=2.1.6->nbdime->-r requirements.txt (line 8)) (4.0.11)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy->-r requirements.txt (line 5)) (2.1.5)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (4.3.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (23.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\guill\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\guill\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (5.7.2)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (7.16.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (0.21.0)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (2.0.13)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\guill\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (26.2.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (0.18.1)\n",
      "Requirement already satisfied: traitlets>=5.6.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (5.14.3)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-server->nbdime->-r requirements.txt (line 8)) (1.8.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->-r requirements.txt (line 7)) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->-r requirements.txt (line 7)) (2021.13.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat->nbdime->-r requirements.txt (line 8)) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat->nbdime->-r requirements.txt (line 8)) (4.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 5)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 5)) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers==4.44.2->-r requirements.txt (line 3)) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers==4.44.2->-r requirements.txt (line 3)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers==4.44.2->-r requirements.txt (line 3)) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers==4.44.2->-r requirements.txt (line 3)) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy->-r requirements.txt (line 5)) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy->-r requirements.txt (line 5)) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 5)) (1.5.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->model2vec->-r requirements.txt (line 9)) (3.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 5)) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 5)) (7.0.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->model2vec->-r requirements.txt (line 9)) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->model2vec->-r requirements.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch->-r requirements.txt (line 7)) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio>=3.1.0->jupyter-server->nbdime->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server->nbdime->-r requirements.txt (line 8)) (21.2.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=2.1.4,!=2.1.5,!=2.1.6->nbdime->-r requirements.txt (line 8)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat->nbdime->-r requirements.txt (line 8)) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat->nbdime->-r requirements.txt (line 8)) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat->nbdime->-r requirements.txt (line 8)) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat->nbdime->-r requirements.txt (line 8)) (0.20.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server->nbdime->-r requirements.txt (line 8)) (4.2.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\guill\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server->nbdime->-r requirements.txt (line 8)) (306)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server->nbdime->-r requirements.txt (line 8)) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server->nbdime->-r requirements.txt (line 8)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server->nbdime->-r requirements.txt (line 8)) (0.1.1)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->model2vec->-r requirements.txt (line 9)) (0.1.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime->-r requirements.txt (line 8)) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime->-r requirements.txt (line 8)) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime->-r requirements.txt (line 8)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime->-r requirements.txt (line 8)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime->-r requirements.txt (line 8)) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime->-r requirements.txt (line 8)) (0.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime->-r requirements.txt (line 8)) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server->nbdime->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server->nbdime->-r requirements.txt (line 8)) (0.5.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server->nbdime->-r requirements.txt (line 8)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server->nbdime->-r requirements.txt (line 8)) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server->nbdime->-r requirements.txt (line 8)) (3.0.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server->nbdime->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server->nbdime->-r requirements.txt (line 8)) (24.8.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server->nbdime->-r requirements.txt (line 8)) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server->nbdime->-r requirements.txt (line 8)) (2.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server->nbdime->-r requirements.txt (line 8)) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server->nbdime->-r requirements.txt (line 8)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server->nbdime->-r requirements.txt (line 8)) (2.9.0.20241003)\n",
      "Downloading model2vec-0.2.3-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: model2vec\n",
      "Successfully installed model2vec-0.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cb0a2e",
   "metadata": {},
   "source": [
    "## 1. IntroducciÃ³n a NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc47014",
   "metadata": {},
   "source": [
    "### 1.1 Ejercicio: Investigar 3 aplicaciones actuales de NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4237df",
   "metadata": {},
   "source": [
    "### 1.2 Ejercicio: Usar la biblioteca nltk o spaCy en Python para tokenizar un texto corto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eb7a8f",
   "metadata": {},
   "source": [
    "#### 1.2.1 Ejercicio con Nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36dc56",
   "metadata": {},
   "source": [
    "##### 1.2.1.1 IntalaciÃ³n de NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ab5736",
   "metadata": {},
   "source": [
    "##### 1.2.1.2 Importar las librerÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6923a91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec8dfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package abc is already up-to-date!\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package alpino is already up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_eng is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger_rus is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown is already up-to-date!\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package chat80 is already up-to-date!\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package city_database is already up-to-date!\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package cmudict is already up-to-date!\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package comtrans is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package crubadan is already up-to-date!\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package dolch is already up-to-date!\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package floresta is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package genesis is already up-to-date!\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ieer is already up-to-date!\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package inaugural is already up-to-date!\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package indian is already up-to-date!\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package jeita is already up-to-date!\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package kimmo is already up-to-date!\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package knbc is already up-to-date!\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package machado is already up-to-date!\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_ne_chunker_tab is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package maxent_treebank_pos_tagger_tab is already\n",
      "[nltk_data]    |       up-to-date!\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package names is already up-to-date!\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw is already up-to-date!\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package paradigms is already up-to-date!\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pe08 is already up-to-date!\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pil is already up-to-date!\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pl196x is already up-to-date!\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package porter_test is already up-to-date!\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ppattach is already up-to-date!\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package propbank is already up-to-date!\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ptb is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package punkt_tab is already up-to-date!\n",
      "[nltk_data]    | Downloading package qc to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package qc is already up-to-date!\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package reuters is already up-to-date!\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rslp is already up-to-date!\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package rte is already up-to-date!\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package semcor is already up-to-date!\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package senseval is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package smultron is already up-to-date!\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package state_union is already up-to-date!\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package swadesh is already up-to-date!\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package switchboard is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets is already up-to-date!\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package tagsets_json is already up-to-date!\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package timit is already up-to-date!\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package toolbox is already up-to-date!\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package treebank is already up-to-date!\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr is already up-to-date!\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
      "[nltk_data]    |       date!\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package webtext is already up-to-date!\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package words is already up-to-date!\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]    |   Package ycoe is already up-to-date!\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65705a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e74d0c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a946ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\guill\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a299848",
   "metadata": {},
   "source": [
    "##### 1.2.1.3 Escribir un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31209251",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_text = \"I am learning about tokenization!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b13422",
   "metadata": {},
   "source": [
    "##### 1.2.1.3 Tokenizar por oraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bead825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentance list: ['I am learning about tokenization!'].\n"
     ]
    }
   ],
   "source": [
    "sentences = sent_tokenize(nltk_text)\n",
    "print(f\"Sentance list: {sentences}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638e2c3d",
   "metadata": {},
   "source": [
    "##### 1.2.1.4 Tokenizar por palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "073b19e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word list: ['I', 'am', 'learning', 'about', 'tokenization', '!'].\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(nltk_text)\n",
    "print(f\"Word list: {words}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994196ea",
   "metadata": {},
   "source": [
    "##### 1.2.1.5 Tokenizar por subpalabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8ab81ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subword list: ['i', 'am', 'learn', 'about', 'token', '!'].\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmer_subwords = [stemmer.stem(word) for word in words]\n",
    "print(f\"Subword list: {stemmer_subwords}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f94dc2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subword list: ['I', 'am', 'learning', 'about', 'tokenization', '!'].\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer_subwords = [lemmatizer.lemmatize(word) for word in words]\n",
    "print(f\"Subword list: {lemmatizer_subwords}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1826e77f",
   "metadata": {},
   "source": [
    "##### 1.2.1.6 Tokenizar por caracteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34448aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character List: ['I', ' ', 'a', 'm', ' ', 'l', 'e', 'a', 'r', 'n', 'i', 'n', 'g', ' ', 'a', 'b', 'o', 'u', 't', ' ', 't', 'o', 'k', 'e', 'n', 'i', 'z', 'a', 't', 'i', 'o', 'n', '!']\n"
     ]
    }
   ],
   "source": [
    "characters = list(nltk_text)\n",
    "print(f\"Character List: {characters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e09289",
   "metadata": {},
   "source": [
    "#### 1.2.2 Ejercicio con spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5111bc6d",
   "metadata": {},
   "source": [
    "##### 1.2.2.1 IntalaciÃ³n de NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00076a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 2.1/12.8 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 4.5/12.8 MB 12.2 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 6.3/12.8 MB 11.0 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.7/12.8 MB 11.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 10.7/12.8 MB 10.5 MB/s eta 0:00:01\n",
      "     --------------------------------------- 12.8/12.8 MB 10.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.2)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\guill\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Attempting uninstall: en-core-web-sm\n",
      "    Found existing installation: en_core_web_sm 3.8.0\n",
      "    Uninstalling en_core_web_sm-3.8.0:\n",
      "      Successfully uninstalled en_core_web_sm-3.8.0\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2mâ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806836f2",
   "metadata": {},
   "source": [
    "##### 1.2.2.2 Importar las librerÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dbd6be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d770c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c1d2e",
   "metadata": {},
   "source": [
    "##### 1.2.2.3 Escribir un texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcb12428",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_text = \"I am learning how to do tokenization with spacy. It is awesome!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff991372",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(spacy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1f94bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am learning how to do tokenization with spacy.\n",
      "It is awesome!\n"
     ]
    }
   ],
   "source": [
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab00e897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'learning',\n",
       " 'how',\n",
       " 'to',\n",
       " 'do',\n",
       " 'tokenization',\n",
       " 'with',\n",
       " 'spacy',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'awesome',\n",
       " '!']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []\n",
    "for token in doc:\n",
    "    words.append(token.text)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5736e1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " ' ',\n",
       " 'a',\n",
       " 'm',\n",
       " ' ',\n",
       " 'l',\n",
       " 'e',\n",
       " 'a',\n",
       " 'r',\n",
       " 'n',\n",
       " 'i',\n",
       " 'n',\n",
       " 'g',\n",
       " ' ',\n",
       " 'h',\n",
       " 'o',\n",
       " 'w',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " ' ',\n",
       " 'd',\n",
       " 'o',\n",
       " ' ',\n",
       " 't',\n",
       " 'o',\n",
       " 'k',\n",
       " 'e',\n",
       " 'n',\n",
       " 'i',\n",
       " 'z',\n",
       " 'a',\n",
       " 't',\n",
       " 'i',\n",
       " 'o',\n",
       " 'n',\n",
       " ' ',\n",
       " 'w',\n",
       " 'i',\n",
       " 't',\n",
       " 'h',\n",
       " ' ',\n",
       " 's',\n",
       " 'p',\n",
       " 'a',\n",
       " 'c',\n",
       " 'y',\n",
       " '.',\n",
       " ' ',\n",
       " 'I',\n",
       " 't',\n",
       " ' ',\n",
       " 'i',\n",
       " 's',\n",
       " ' ',\n",
       " 'a',\n",
       " 'w',\n",
       " 'e',\n",
       " 's',\n",
       " 'o',\n",
       " 'm',\n",
       " 'e',\n",
       " '!']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters = list(spacy_text)\n",
    "characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d227308c",
   "metadata": {},
   "source": [
    "## 2. Embeddings y Representaciones Vectoriales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6e946",
   "metadata": {},
   "source": [
    "### Ejercicio: Cargar un modelo de word embeddings de Hugging Face (por ejemplo, glove o word2vec) y visualizar los embeddings de palabras similares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0363cd7",
   "metadata": {},
   "source": [
    "### Ejercicio: Comparar GloVe (estÃ¡tico) con BERT (dinÃ¡mico) mediante un ejemplo prÃ¡ctico en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fd8259",
   "metadata": {},
   "source": [
    "## 3. Modelos Basados en Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1960ed7",
   "metadata": {},
   "source": [
    "### Ejercicio: Implementar una RNN simple para predicciÃ³n de secuencias en Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26f9054",
   "metadata": {},
   "source": [
    "### Ejercicio: Utilizar el modelo de transformers BERT o GPT-2 de Hugging Face para completar una frase simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a549c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fb9f543",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Being a computer scientist is all about [MASK].\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793a713f",
   "metadata": {},
   "source": [
    "#### Utilizar BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89e1a50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f30577ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.11361566185951233,\n",
       "  'token': 7588,\n",
       "  'token_str': 'computers',\n",
       "  'sequence': 'being a computer scientist is all about computers.'},\n",
       " {'score': 0.06099285930395126,\n",
       "  'token': 2671,\n",
       "  'token_str': 'science',\n",
       "  'sequence': 'being a computer scientist is all about science.'},\n",
       " {'score': 0.05559048056602478,\n",
       "  'token': 2009,\n",
       "  'token_str': 'it',\n",
       "  'sequence': 'being a computer scientist is all about it.'},\n",
       " {'score': 0.048937588930130005,\n",
       "  'token': 2470,\n",
       "  'token_str': 'research',\n",
       "  'sequence': 'being a computer scientist is all about research.'},\n",
       " {'score': 0.031744930893182755,\n",
       "  'token': 8785,\n",
       "  'token_str': 'math',\n",
       "  'sequence': 'being a computer scientist is all about math.'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = bert_mask(text)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748b30bd",
   "metadata": {},
   "source": [
    "#### Utilizar GPT 2 TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f36f38c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_mask = pipeline(\"fill-mask\", model=\"gpt2\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5592502c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Being a computer scientist is all about [MASK]. It's all about finding the perfect balance and finding the best solution. A lot of students may be a little surprised that some of them get so far [at a point] to realize that there\"}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2_prediction = gpt2_mask(text)\n",
    "gpt2_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9df00d0",
   "metadata": {},
   "source": [
    "## 4. Modelos Pre-entrenados y Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade7df70",
   "metadata": {},
   "source": [
    "### Pregunta 7: Â¿QuÃ© significa que un modelo estÃ© preentrenado? Â¿CÃ³mo se puede ajustar para una tarea especÃ­fica?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9dfe86",
   "metadata": {},
   "source": [
    "#### Ejercicio: Usar un modelo de Hugging Face (distilBERT) para clasificar un conjunto de datos de sentimientos (usar el dataset de Rotten tomatoes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10309397",
   "metadata": {},
   "source": [
    "### Pregunta 8: Â¿QuÃ© es el enmascaramiento de palabras en el preentrenamiento de modelos como BERT?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47691e9",
   "metadata": {},
   "source": [
    "#### Ejercicio: Usar BERT para predecir palabras enmascaradas en una oraciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "883fdf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9c4c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Being a computer scientist is all about [MASK].\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "38cd6370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00cc48a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.11361566185951233,\n",
       "  'token': 7588,\n",
       "  'token_str': 'computers',\n",
       "  'sequence': 'being a computer scientist is all about computers.'},\n",
       " {'score': 0.06099285930395126,\n",
       "  'token': 2671,\n",
       "  'token_str': 'science',\n",
       "  'sequence': 'being a computer scientist is all about science.'},\n",
       " {'score': 0.05559048056602478,\n",
       "  'token': 2009,\n",
       "  'token_str': 'it',\n",
       "  'sequence': 'being a computer scientist is all about it.'},\n",
       " {'score': 0.048937588930130005,\n",
       "  'token': 2470,\n",
       "  'token_str': 'research',\n",
       "  'sequence': 'being a computer scientist is all about research.'},\n",
       " {'score': 0.031744930893182755,\n",
       "  'token': 8785,\n",
       "  'token_str': 'math',\n",
       "  'sequence': 'being a computer scientist is all about math.'}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = bert_mask(text)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870140cb",
   "metadata": {},
   "source": [
    "## 5. Tareas ClÃ¡sicas de NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e938d75",
   "metadata": {},
   "source": [
    "### Pregunta 9: Â¿QuÃ© es la clasificaciÃ³n de texto y quÃ© modelos se suelen utilizar para esta tarea?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946135f3",
   "metadata": {},
   "source": [
    "#### Ejercicio: Implementar un modelo NER utilizando spaCy o Hugging Face y aplicar etiquetas a un conjunto de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff632c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a000aa1f",
   "metadata": {},
   "source": [
    "### Pregunta 10: Â¿QuÃ© es el anÃ¡lisis de sentimientos y cÃ³mo se relaciona con la clasificaciÃ³n de texto?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827fa79d",
   "metadata": {},
   "source": [
    "#### Ejercicio: Utilizar Hugging Face para hacer anÃ¡lisis de sentimientos en un conjunto de datos de reseÃ±as (usar el dataset de IMDB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60f0849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abbdc21a",
   "metadata": {},
   "source": [
    "## 6. GeneraciÃ³n de Texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bb2cbf",
   "metadata": {},
   "source": [
    "### Ejercicio: Usar Hugging Face para generar texto a partir de un prompt con GPT-2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c004df",
   "metadata": {},
   "source": [
    "### Ejercicio: Discutir sobre sesgos en los modelos de lenguaje generativo y su impacto en aplicaciones reales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae312f3",
   "metadata": {},
   "source": [
    "## 7. EvaluaciÃ³n de Modelos NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd0515c",
   "metadata": {},
   "source": [
    "### Ejercicio: Usar mÃ©tricas como accuracy, precision, y recall para evaluar un modelo de clasificaciÃ³n de texto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e460386",
   "metadata": {},
   "source": [
    "### Ejercicio: Calcular la perplejidad de un modelo de lenguaje en Hugging Face para una tarea de generaciÃ³n de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129a82a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
